\section{Related Work}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

Weatherspoon et al. establish a strong case for erasure coded storage systems~\ref{weatherspoon2002erasure}. They demonstrate that such systems consume an order of magnitude less bandwidth and storage to provide similar durability as replicated systems.

{\bf Erasure Coding in Cluster Storage:}
Erasure coding has long been applied in many large-scale distributed storage systems~\ref{bib:saito2004fab, bib:zhang2004repstore, haeberlen2005glacier, bib:abd2005ursa, welch2008scalable, sathiamoorthy2013xoring, zhang2016efficient}, including productions systems at Facebook~\ref{borthakur2010hdfs}, Google~\ref{fikes2010storage, ford2010availability} and Microsoft Azure~\ref{huang2012erasure}. These solutions generalize the RAID approach~\ref{patterson1988case, wilkes1996hp} to a distributed cluster setting. Giza synchronously replicates erasure coded data across WAN. Since the latency across WAN is much higher than in a cluster, Giza focuses on minimizing round trips so as to optimize latency. In addition, Giza provides globally consistent {\em get} and {\em put} with versioning support.

{\bf Erasure Coding across WAN Storage:}
OceanStore \ref{OceanStore, bib:pond} employs erasure coding and encryption to achieve a global-scale persistent storage. It assumes a fundamentally untrusted infrastructure. To achieve strong consistency, OceanStore serializes updates via a primary tier of replicas, a generalized form of primary. These primary replicas cooperate in a Byzantine agreement protocol to choose the final commit order for the updates. In comparison, Giza operates in a trusted environment and employs leaderless consensus protocols. Updates may originate from arbitrary data centers and still complete with optimal latency. There is no need to relay all the updates through the primaries.

HAIL~\ref{Bowers:2009:HHI:1653662.1653686}, RACS~\ref{Abu-Libdeh:2010:RCC:1807128.1807165} and NCCloud~\ref{hu2012nccloud} all stripe and erasure code data across multiple cloud storage providers. 
HAIL~\ref{Bowers:2009:HHI:1653662.1653686} applies error correction coding within individual providers and erasure coding across them. It is designed to withstand Byzantine adversaries and unifies proofs of retrievability and failure recovery. Giza operates in trustworthy environment and exploits the trade-off among storage cost, network bandwidth and durability.

RACS~\ref{Abu-Libdeh:2010:RCC:1807128.1807165} 
%tolerates outages and mitigates vendor lock-in with reasonable overhead cost. It 
builds a working system that is compatible with existing cloud storage clients and able to use multiple storage providers as back-ends.
It addresses the conflict caused by concurrent writers using Apache ZooKeeper~\ref{zookeeper}, where readers-writer locks are implemented at per-key granularity to synchronize distributed RACS proxies.
Giza, on the other hand, implements consensus algorithms for individual keys and achieves strong consistency without centralized coordinators.

NCCloud~\ref{hu2012nccloud} advances state-of-the-art on erasure coding and implements a class of functional regenerating codes~\ref{Dimakis07networkcoding} that optimize cross-WAN repair bandwidth. Giza employs standard Reed-Solomon coding and leaves innovation on erasure coding to future exploration.

Facebook F4~\ref{muralidhar2014f4} is a production warm blob storage system, storing over 65PBs of logical data. It applies erasure coding across data centers and reduces effective-replication-factor from 3.6 to 2.1. As discussed earlier, F4 doesn't reclaim the space occupied by deleted objects, which wastes $6.8\%$ of total storage. F4's choice is not an option for Giza, due to much higher deletion rate in cloud storage, as well as compliance requirements.

\comment{
There are two general approaches in applying erasure coding to storage.  One
is to generate coded fragments within each data object.  This is commonly used
to achieve redundancy within a single data center~\cite{facebook:f4}.  Another 
approach is to treat multiple data objects as a coding group and generate
parity blocks that combine multiple objects.  Facebook's cross-DC erasure
coding uses this scheme to code immutable blobs.  To handle mutable coded
blocks, prior work resort to a RAID-like approach~\cite{haibo:fast} of using
static coding groups comprising of fixed sized blocks. The RAID approach has
only been applied in cluster settings.
}

{\bf Separating Data from Metadata:}


{\bf Consistency in Global Storage}
MDCC, Mencius


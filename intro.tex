\section{Introduction}

Microsoft Azure Storage is a global cloud storage system with a footprint in 38 geographic
regions~\cite{bib:azureregions}. Since 2010, Azure Storage has grown from tens of
petabytes to many exabytes, with tens of trillions of objects stored~\cite{greenberg15sdn}.

To protect customer data against disk, node, and rack failure within a data
center (DC), Azure Storage applies Local Reconstruction Coding (LRC)~\cite{huang12erasure}
to ensure high availability and durability. 
LRC significantly reduces the storage cost over the conventional scheme of
three-way replication.

To further protect customer data against catastrophic data center failures
(say due to earthquake, tsunami, etc.),
Azure Storage optionally replicate customer data to secondary DCs hundreds of miles away.
It is essential to the customers that even in the unlikely, albeit inevitable,
event of catastrophic data center failure, their data remain durable.

Geo-replication, however, doubles the storage cost.
With many exabytes at present and exponential growth projected,
it is highly desirable to lower the storage cost
required for maintaining geo-redundancy.

\input{fig_moti}

\subsection{Cross-DC Erasure Coding: Why Now?}

Erasure coding across geographically distributed DCs is an appealing option.
It has the potential to ensure durability in the face of data center failure
while significantly reducing storage cost compared to geo-replication.
The same economic argument that has driven cloud providers to erasure code data
within individual data centers naturally extends to the cross-DC scenario.

However, when customer data is erasure coded and striped across multiple DCs, 
serving read requests would require data retrieval from remote DCs, resulting in
cross-DC network traffic and latency. Furthermore, the recovery after catastrophic
DC failure would trigger wide-area erasure coding reconstruction. While such
reconstruction can be paced and prioritized based on demand, it nevertheless
requires sufficient cross-DC network bandwidth to ensure timely recovery.

Therefore, cross-DC erasure coding only becomes economically attractive if 1)
there are workloads that consume very large storage capacity while incurring very
little cross-DC traffic; 2) there are enough cross-DC network bandwidth at very
low cost.

For the former, Azure Storage indeed serves many customers
with such workloads. Using Microsoft OneDrive as an example,
Section~\ref{sec:motivation} illustrates the characteristics of typical cloud storage workloads
and why they are ideal for cross-DC erasure coding.
For the latter, recent technological breakthroughs~\cite{mears1986low, zhu2011112}
have dramatically increased bandwidth and reduced cost in cross-DC networking.
For example, Facebook and Microsoft have teamed up to build \textit{MAREA},
a new fiber optic cable under the Atlantic Ocean 
that will come online in 2017 with 160 Tbps capacity~\cite{bib:MAREA1, bib:MAREA2}.
The significant advancement in cross-DC networking is now making cross-DC erasure coding economically viable.

\comment{bib:MAREA1, http://www.wsj.com/articles/facebook-and-microsoft-to-build-fiber-optic-cable-across-atlantic-1464298853}
\comment{bib:MAREA2, http://www.usatoday.com/story/experience/2016/05/26/microsoft-facebook-undersea-cable-google-marea-amazon/84984882/}
\comment{bib:FA-1, https://en.wikipedia.org/wiki/Fiber-Optic_Link_Around_the_Globe}

\subsection{Challenges and Contributions}
This paper presents Giza, a cloud object store that erasure codes and stripes
customer data across globally distributed DCs.  We aim to achieve two design
goals. One, Giza should guarantee strong consistency while also minimizing
operation latency.  The other, Giza should make full use of existing cloud
infrastructure to simplify its implementation and deployment.

Since reads and writes requires cross-DC communication, latency is minimized 
when operations can complete within a single cross-DC roundtrip.  This is 
possible to achieve for our target workloads (e.g. OneDrive), where 
objects are updated infrequently.
Nevertheless, concurrent updates to the same object do exist.
Furthermore, such conflicting access might originate from different DCs.
%Giza needs to ensure strong consistency when conflicts occur. This becomes
%particularly interesting as Giza allows requests to originate from any DC.
Consider two concurrent requests updating the same object (with different data)
from two separate DCs. Depending on network latency, the two requests may
arrive at different data centers in different order. If not handled properly,
this would result in data inconsistency.  

To ensure strong consistency, one
possible approach is to dedicate a primary DC that handles all updates and
enforces execution order. However, requests from non-primary data centers have
to be relayed to the primary first, incurring extra cross-DC latency, even when
there are no concurrent updates. To guarantee strong consistency while
minimizing latency in the common case, Giza employs 
FastPaxos~\cite{lamport05fast}, which incurs a single cross-DC roundtrip when
there are no concurrent updates.  When conflicting access do sometimes occur,
Giza uses classic Paxos~\cite{lamport01paxos} and may take multiple cross-DC
round trips to resolve the conflicts. We deem this to be an acceptable
tradeoff. 

We implement Giza on top of the existing Azure storage infrastructure.  For
each object, Giza stores its coded fragments in the Azure Blob storage of
different DCs, and replicates its versioned meta-data containing the ids of 
coded fragments in the Azure Table storage of multiple DCs.  Giza guarantees
the consistency of versioned meta-data using Paxos/FastPaxos and it adapts both
protocols to use the existing APIs of Azure Table storage.

%An ideal solution should optimize for the common case.
%When there are no concurrent updates, 
%reads and writes originating from any DC should complete within single cross-DC round trip.
%In addition, the ideal solution should ensure strong consistency in the rare case,
%when concurrent updates to the same object do sometimes occur.
%It is expected and acceptable that latency would increase
%as it takes multiple cross-DC round trips to resolve the conflicts.

To summarize, this paper makes the following contributions:
\begin{itemize}
    \item We have designed and implemented Giza, a strongly consistent,
      versioned object store that erasure codes objects across globally
      distributed data centers.
    \item Giza achieves minimum latency in the common case when there are no concurrent conflicting access, and ensures strong consistency in the rare case under contention.
    \item Giza applies well-known distributed protocols-- Paxos~\cite{lamport01paxos}
      and Fast Paxos~\cite{lamport05fast} -- in a novel way on top of restricted cloud storage APIs.
    \item Giza is deployed in \deployment and experimental results demonstrate
      that it achieves our design goals.
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

\section{Introduction}

\comment{

Giza is a cloud storage front end that erasure codes large mutable data files across multiple data centers . The motivation of Giza is to reduce overall storage cost and to tolerate entire data center failures, while maintaining strong consistency and reasonable read and write latencies.

\par
We have made the following contributions in this paper. First, we observed that cross-data center network bandwidth grow rapidly. This, coupled with the rapid growth in cloud storage capacity, strongly motivates the use of cross WAN erasure coding in practice. Second, we have designed a cross WAN erasure coded key-value storage which relies on limited interface supported by many existing cloud APIs such as Azure and AWS. This key-value store is strongly consistent and can tolerate complex network partitions. Lastly, we have implemented this system as a frontend on top of the Azure storage and demonstrated that such a system can replace current solutions for write heavy workloads.

\subsection{Background}
Paxos is a consensus algorithm that satisfies the safety property in an asynchronous network. 
\par
Erasure Encoding is a very mature technique used in storage systems for data striping and fault tolerance.

%\subsection{}
Project Giza stores erasure coded data objects across multiple geographically distributed data centers. It provides the same or higher level of durability than geo-replication, but at much reduced storage cost. Project Giza leverages existing cloud storage APIs and operates on the top of existing public clouds.

}

\subsection{Cross-DC Erasure Coding: Why Now?}

As the entire IT industry is rapidly moving to cloud, and more and more data center is built all over the world, the probabiliy that a single data center will fail catastrophically becomes inevitable. It is essential that the data stored in the cloud is protected against such catastrophical failure. 

There have been a long line of prior work~\ref{bib:BlahBlah} arguing for storing data objects in erasure coded form, as opposed to replication, across geo-graphically distributed data centers. Similar to geo-replication, cross-DC erasure coding can ensure durability even in the event of massive data center failures. A main motivation for Cross-DC erasure coding is to significantly reduce storage cost compared to geo-replication. The same economis force that has powered clous storage providers to erasure code data within individual data centers extends natually to the cross-DC scenario.

Nevertheless, none of the cloud storage providers today offer options for customers to erasure code their data across data centers. This is largely due to the current cost of WAN bandwdith. The reduction in storage cost of cross-DC erasure coding comes at the cost of inflated WAN traffic during normal read/write work flow, as well as in the event of massive data center failure. With geo-replication, normal read operation is served from single primary data center, so there is no WAN traffic. In the event of data center failure, all reads can completely fail-over to the secondary data center, where there is again no stress on the WAN backbone. With cross-DC erasure coding, however, both normal reads and fail-over reads incur non-trivial WAN traffic. Since the total cost of cloud storage includes both the storage alone cost and the WAN cost, cross-DC erasure coding has not been an economic solution.

Nevertheless, the technology advancement in wide area networking has progressed to a point where new innovation is greatly reducing WAN bandwidth cost. There are two key driving forces. The erbium-doped fiber amplifiers~\ref{bib:mears} makes it possible to amplifies a huge spectrum of optical signal directly, with the need to first convert it to an electrical signal. This enables Dense Wave Divsion Multiplexing (DWDM), which make it possible to send 10+ terabits per single fiber~\ref{bib:below}. 

\Comment{
Mears, R.J. and Reekie, L. and Poole, S.B. and Payne, D.N.: "Low-threshold tunable CW and Q-switched fiber laser operating at 1.55Î¼m", Electron. Lett., 1986, 22, pp.159-160

Zhu, B., et al. "112-Tb/s space-division multiplexed DWDM transmission with 14-b/s/Hz aggregate spectral efficiency over a 76.8-km seven-core fiber." Optics Express 19.17 (2011): 16665-16671.
}
Most recently, Facebook Inc. and Microsoft Corp. have teamed up to build a new fiber optic cable under the Atlantic Ocean, which uses eight pairs of fiber optic strands and comes online in 2017 with 160 terabits per second capacity~\ref{bib:MAREA1, bib:MAREA2}.

{\bf TODO: make the below a table}

TransAtlantic Undesea Cable     | FLAG Atlantic 1~\ref{bib:FA-1}    | MAREA~\ref{bib:MAREA1, bib:MAREA2}
Ready For Service (RFS)         | 2001                              | 2017
Cost (Billion)                  | 1.1                               | undisclosed
Capacity                        | 10 Gbps                           | 160 Tbps

\comment{bib:MAREA1, http://www.wsj.com/articles/facebook-and-microsoft-to-build-fiber-optic-cable-across-atlantic-1464298853}
\comment{bib:MAREA2, http://www.usatoday.com/story/experience/2016/05/26/microsoft-facebook-undersea-cable-google-marea-amazon/84984882/}
\comment{bib:FA-1, https://en.wikipedia.org/wiki/Fiber-Optic_Link_Around_the_Globe}

\subsection{Giza Overview}

Giza provides an externally consistent (linearizable~\ref{bib:linearizable}) versioned object store, which erasure codes data objects and stores them across globally distributed data centers.

Customers access Giza service by creating special Giza storage accounts, which is similar to today's cloud storage accounts. In addition to storing data within single data center, across multiple availability zones within a region, or across two geo-graphically distributed data centers, Giza storage accounts allow the customers to specify the set of data centers where their data is striped across, as well as the resulted total storage overhead.

The customers access Giza service with simple put/get/delete interface. In addition to standard object storage interface, Giza provides addtional option to support versioning, where new put requests will not overwrite an existing object, but rather create new versions of the same object. The old versions remain in the system and accessible until they are explicitly removed.

Giza operates on the top of existing cloud storage systems and leverages their public APIs. It uses blob storage to store customer data objects and nosql table storage to store metatadata.

Figure~\ref{fig:giza_example} illustrates the work flow of putting a customer data object. Giza operates a group of {\em stateless} Giza nodes in every data center. Say a customer uses Giza clients (command line, library for various programming language, or REST interface) to put a 4MB data object. The Giza client routes the request to one of the Giza nodes in the data center closest to the customer. The Giza node divides the data object into 2 data fragments ($a$ and $b$), with each fragment being 2MB. It then invokes an erasure coding process and generates a parity fragment of 2MB. The Giza node disperses and stores the 3 fragments (2 data and 1 parity) in the blob storage in 3 data centers (1 local and 2 remote). The pointers to the 3 blob storage, together with versioning information, form the metadata of the customer data object. The Giza node persists the metadata in the nosql table storage in the 3 data centers.

\subsection{Challenges and Contributions}

Giza tolerates data center failures. Even in the event of massive data center failure, the customers need to be able to continuously get existing data objects, update them, or put new ones.

Giza supports concurrent gets and puts. While the blob storage and nosql table storage within individual data centers operate independently, Giza needs to coordinate all the accesses so as to achieve external consistency (linerizability).

The workloads that Giza target don't have high concurrency. This means that single reader / writer is the common case and Giza strives to {\em make the common case fast}. On the other hand, concurrency do arise in various situations, such as failures or uncommon usage. Even though concurrency is a rare case, Giza needs to {\em guarantee the rare case correct}. The technical challengue turns out to be how to achieve both the above, even in the event of massive data center failure.

Towards this end, we have made the following contributions:
\begin{itemize}
    \item We have designed and implemented Giza, which provides a versioned object store that erasure codes data objects and stores them across globally distributed data centers.
    \item Giza is fast in the common case: when there is no concurrency, Giza completes within single WAN RTT, which is optimal given the requirement to tolerate data center failure.
    \item Giza is correct in the rare case: under concurrency and with data center failure, Giza achieves external consistency (linearizability).
    \item Giza employs well-known distributed algorithms, such as Paxos and Fast Paxos, in a novel way so that it operates on the top of exsiting public cloud storage systems.
    \item Giza is deployed in xxx data centers. Trace-driven experiments demonstrate that Giza achieve all our design goals. In particular, it is worth pointing out that Giza achieves much lower latency than naively adopting a globally consistent storage system, like Google's spanner.
\end{itemize}

\section{A Case for Giza}

\subsection{The Need for Flexibility}

Erasure coding across geo-graphically distributed data centers is a most effective approach to reduce storage cost while achieving the fault tolerance goal of being able to survive data center failure. As Facebook's F4 system~\ref{bib:F4} has demonstrated, replacing geo-replication with cross-DC erasure coding can effectively reduce storage overhead from 3.6x to 2.1x, achieving huge savings for Facebook's 65PB of worm storage. While a fixed 2 + 1 solution works very well for Facebook's special workload, the public cloud storage desires much more flexibility. Different customers have different desirable operating points in terms of cost, durability and latency trade-off and are willing to accept different pricing for different needs. This creates an opportunity to offer flexible cross-DC erasure coding options.

Giza provide completes flexibility to the customers. When a storage account is created, the customers have total freedom to specific which set of data centers, what type of erasure coding schemes and how much fault tolerance at the storage account level. In addition, the customer had additional flexibility to specific which data centers are involved, so that they could constraint all the data to be in the United States per data sovereignty requirement and regulation, or they could choose to disperse the erasure coded data across multiple continent, so that no single country could gain access to the complete data.

The default configuration applies $k+1$ erasure coding, where each data object is divided into $k$ data fragments and $1$ single parity fragment is generated from the $k$ data fragments. Here, all the $k+1$ fragments are persisted in $k+1$ data centers. In addition to the default configuration, the customer could 
The default configuration applies $k+1$ erasure coding, where each data object is divided into $k$ data fragments and $1$ single parity fragment is generated from the $k$ data fragments. Here, all the $k+1$ fragments are persisted in $k+1$ data centers. In addition to the default configuration, the customer could create storage accounts with {\em enhanced durability}, where 2 parity fragments are generated from the $k$ data fragments. The resulted $k+2$ erasure coding scheme would tolerate arbitrary 2 data center failures and therefore achieve much higher durability than the standard solution. As shown in the below table~\ref{tab:cost_benefit}, compared to the geo-replication, the enhanced durability is able to achieve much higher durability while still reducing storage cost.

\subsection{Storage & Bandwdith Trade-off}

{\bf add the cost-benefit table from the slide deck here}

\subsection{Alternative Approach}

To store a data object, Giza splits the object into multiple data fragments and generate parity fragments from the data fragments. Both data and parity fragments are dispersed and persisted at different data centers. To serve the data object, Giza reads enouch data and parity fragments from multiple data centers and reconstructs the data object. Hence, all Giza reads incur WAN traffic.

This design decision is a delibrate choice after careful considration of alternative approaches. One viable alternative is to first aggregate data objects into logical volumes and erasure code across different volumes. For instance, data objects in data center A are aggregated into $vol_A$ and data objects in data center B into $vol_B$. Each of the volume is large, say in the order of 100GB. The erasure coding process then takes both $vol_A$ and $vol_B$,  generates a parity volume $vol_P$ and stores $vol_P$ in data center C. In this approach, reading individual data object occurs in its corresponding data center and avoids WAN traffic. The challenge, however, is to handle object deletion. When a data object is deleted from $vol_A$ in data center A, it needs to be sent across WAN so that it can be {\em canceled} from $vol_C$. This adds great engineering complexity.

Facebook F4 system adtops this approach and avoids the problem completely by not deleting data objects. In F4, every data object is encrypted with a unique key. When a data object in $vol_A$ is deleted, its unique key is destroyed while the encrypted data object remains in the volume. Such simplification suits Facebook very well, as it can afford to not reclaiming the storage space occupied by the  $6.8\%$ deleted data. This, unfortunately, is not an option for us. First, our workloads demonstrate much larger deletion rate. Employing same simplification would result in much higher cost for us. Secondly, not physically deleting customer data - even if encrypted - wouldn't meet the compliance requirements for many of our customers.

Given these considerations, Giza chooses to split individual data objects and incur WAN traffic and latency during object retrival. Since the workload Giza targets is rather cold (very small numbers of reads over a large corpus of data), this choices works out very well.